x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

x-restart: &default-restart
  restart: unless-stopped

x-deploy: &default-deploy
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 512M
      reservations:
        cpus: '0.25'
        memory: 256M

services:
  # NGINX - Optional
  # nginx-proxy:
  #   image: nginx
  #   container_name: nginx-proxy
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf
  #     - ./nginx/certs:/etc/nginx/certs
  #   depends_on:
  #     - api-gateway
  #   networks:
  #     - backend-network
  #   restart: unless-stopped
  #   profiles:
  #     - nginx  # Optional: docker-compose --profile nginx up

  # API Gateway - internal only (use nginx-proxy profile to expose 80/443)
  api-gateway:
    build:
      context: ./api-gateway
    container_name: api-gateway
    ports:
      - "8000:8000"
    env_file:
      - ./api-gateway/.env
    environment:
      - NEED_EMAIL_VERIFICATION=false  # Easier for dev
      - NEED_API_KEY=false
      - SEND_ACCESS_TOKEN_TO_CLIENT=false  # For dev testing
    volumes:
      - ./api-gateway:/app
      - /app/node_modules
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  # All microservices - EXPOSE ONLY (no external ports)
  auth-service:
    build:
      context: ./auth-service
    container_name: auth-service
    expose:
      - "8001"  # External port for Postman/Frontend
    env_file:
      - ./auth-service/.env
    environment:
      - NEED_EMAIL_VERIFICATION=true  # Easier for dev
      - NEED_API_KEY=false
      - SEND_ACCESS_TOKEN_TO_CLIENT=false  # For dev testing
      - NOTIFICATION_EVENTS_ENABLED=true
    volumes:
      - ./auth-service:/app
      - /app/node_modules
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  notification-service:
    build:
      context: ./notification-service
    container_name: notification-service
    expose:
      - "8009"
    env_file:
      - ./notification-service/.env
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=notification_db
      - DB_USER=notification_service
      - DB_PASSWORD=1
    volumes:
      - ./notification-service:/app
      - /app/node_modules
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8009/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  user-service:
    build:
      context: ./user-service
    container_name: user-service
    expose:
      - "8002" 
    env_file:
      - ./user-service/.env
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=redispass123
    volumes:
      - ./user-service:/app
      - /app/node_modules
      - ./libs:/libs
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  transport-service:
    build:
      context: ./transport-service
    container_name: transport-service
    expose:
      - "8003"    # Internal HTTP
      - "50051"   # Internal gRPC
    env_file:
      - ./transport-service/.env
    volumes:
      - ./transport-service:/app
      - /app/node_modules
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  ticket-service:
    build:
      context: ./ticket-service
    container_name: ticket-service
    expose:
      - "8004"    # Internal HTTP
      - "50052"   # Internal gRPC
    env_file:
      - ./ticket-service/.env
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=redispass123
    volumes:
      - ./ticket-service:/app
      - /app/node_modules
      - ./libs:/libs
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  public-service:
    build:
      context: ./public-service
    container_name: public-service
    expose:
      - "8005"  # Internal only
    env_file:
      - ./public-service/.env
    environment:
      - SCHEDULER_ENABLED=true
      - TRANSPORT_SERVICE_GRPC_URL=transport-service:50051
      - TICKET_SERVICE_GRPC_URL=ticket-service:50052
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=redispass123
    volumes:
      - ./public-service:/app
      - /app/node_modules
    depends_on:
      transport-service:
        condition: service_healthy
      ticket-service:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy


  payment-service:
    build:
      context: ./payment-service
    container_name: payment-service
    expose:
      - "8006"  # Internal only
    env_file:
      - ./payment-service/.env
    volumes:
      - ./payment-service:/app
      - /app/node_modules
    depends_on:
      postgres:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8006/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<: *default-restart

  report-service:
    build:
      context: ./report-service
    container_name: report-service
    expose:
      - "8007"  # Internal only
    env_file:
      - ./report-service/.env
    volumes:
      - ./report-service:/app
    command: ["python", "src/main.py"]
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','8007'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<: *default-restart
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  control-service:
    build:
      context: ./control-service
    container_name: control-service
    expose:
      - "8008"   # Internal only
      - "50053"   # Internal gRPC
    env_file:
      - ./control-service/.env
    volumes:
      - ./control-service:/app
    depends_on:
      transport-service:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','8008'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  # Webhook Service - External port for PayPal and other webhook providers
  webhook:
    build:
      context: ./webhook
    container_name: webhook
    ports:
      - "3003:3003"  # External port for webhook providers (PayPal, etc.)
    env_file:
      - ./webhook/.env
    volumes:
      - ./webhook:/app
      - /app/node_modules
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy


  healthcheck:
    build:
      context: ./deploy/healthcheck
    container_name: healthcheck
    expose:
      - "3000"  # Internal only
    env_file:
      - ./deploy/healthcheck/.env
    environment:
      - WEB_CONCURRENCY=2
    volumes:
      - ./deploy/healthcheck:/app
    depends_on:
      redis:
        condition: service_healthy
      
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','3000'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<: *default-restart

  management-service:
    build:
      context: ./management-service
    container_name: management-service
    expose:
      - "3001"
    env_file:
      - ./management-service/.env
    volumes:
      - ./management-service:/app
    networks:
      - backend-network
    depends_on:
      postgres:
        condition: service_healthy
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','3001'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
      
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./management-service/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./management-service/prometheus/alert-rules.yml:/etc/prometheus/alert-rules.yml
      - ./management-service/prometheus/services.json:/etc/prometheus/services.json
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    ports:
      - "9090:9090"
    networks:
      - backend-network
    restart: unless-stopped
    depends_on:
      api-gateway:
        condition: service_healthy
      auth-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
      transport-service:
        condition: service_healthy
      ticket-service:
        condition: service_healthy
      public-service:
        condition: service_healthy
      payment-service:
        condition: service_healthy
      report-service:
        condition: service_healthy
      management-service:
        condition: service_healthy
      healthcheck:
        condition: service_healthy

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./management-service/prometheus/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
    networks:
      - backend-network
    restart: unless-stopped
    depends_on:
      prometheus:
        condition: service_started

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./dashboard/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./dashboard/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./dashboard/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
      - loki
    networks:
      - backend-network
    restart: unless-stopped

  loki:
    image: grafana/loki:2.9.4
    container_name: loki
    ports:
      - "3100:3100"
    command:
      - -config.file=/etc/loki/local-config.yaml
    networks:
      - backend-network
    restart: unless-stopped

  promtail:
    image: grafana/promtail:2.9.4
    container_name: promtail
    volumes:
      - ./management-service/promtail-prod-config.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command:
      - -config.file=/etc/promtail/config.yml
      - -config.expand-env=true
    depends_on:
      - loki
    networks:
      - backend-network
    restart: unless-stopped

  # Infrastructure - External ports for dev tools
  # postgres:
  #   image: postgres:15-alpine
  #   container_name: postgres
  #   env_file:
  #     - ./init_db.env
  #   ports:
  #     - "5432:5432"  # External cho dev tools (pgAdmin, DBeaver, etc.)
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #     - ./init_db.sql:/docker-entrypoint-initdb.d/init_db.sql:ro
  #     # - ./init_db.sh:/docker-entrypoint-initdb.d/99_init_db.sh:ro
  #   networks:
  #     - backend-network
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U postgres"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1.0'
  #         memory: 1G
  #       reservations:
  #         cpus: '0.5'
  #         memory: 512M

  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - "5432:5432"  # External cho dev tools (pgAdmin, DBeaver, etc.)
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init_db.sql:/docker-entrypoint-initdb.d/init_db.sql:ro
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # MongoDB for webhook service
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    ports:
      - "27017:27017"  # External for dev tools (Mongo Compass, etc.)
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=mongopass123
      - MONGO_INITDB_DATABASE=webhook_db
      - WEBHOOK_DB_USER=webhook_user
      - WEBHOOK_DB_PASSWORD=webhook_pass123
    volumes:
      - mongodb_data:/data/db
      - ./init_mongo.sh:/docker-entrypoint-initdb.d/init_mongo.sh:ro
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # MongoDB management interface
  mongo-express:
    image: mongo-express:1.0.2
    container_name: mongo-express
    ports:
      - "8082:8081"  # External for dev - MongoDB web interface
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=admin
      - ME_CONFIG_MONGODB_ADMINPASSWORD=mongopass123
      - ME_CONFIG_MONGODB_URL=mongodb://admin:mongopass123@mongodb:27017/
      - ME_CONFIG_BASICAUTH_USERNAME=admin
      - ME_CONFIG_BASICAUTH_PASSWORD=mongopass123
      - ME_CONFIG_MONGODB_ENABLE_ADMIN=true
    depends_on:
      - mongodb
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379" 
    volumes:
      - redis_data:/data
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: ["redis-server", "--requirepass", "redispass123"]
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Management UIs - External ports
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    environment:
      - REDIS_HOSTS=local:redis:6379:0:redispass123
    ports:
      - "8081:8081"  # External cho dev
    depends_on:
      - redis
    networks:
      - backend-network

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    ports:
      - "5050:80"  # External cho dev
    depends_on:
      - postgres
    networks:
      - backend-network
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      - ./servers.json:/pgadmin4/servers.json:ro

  # Kafka - Internal only 
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 5
      ZOOKEEPER_INIT_LIMIT: 10
    expose:
      - "2181"
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  kafka-1:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-1
    expose:
      - "9092"
      - "19092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
      - zookeeper
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:19092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  kafka-2:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-2
    expose:
      - "9093"
      - "19093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:19093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 2
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
      - zookeeper
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:19093", "--list"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
  kafka-3:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-3
    expose:
      - "9094"
      - "19094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:19094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 3
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
      - zookeeper
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:19094", "--list"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # # Kafdrop - External port cho dev
  # kafdrop:
  #   image: obsidiandynamics/kafdrop
  #   container_name: kafdrop
  #   ports:
  #     - "9000:9000"  # External cho dev
  #   environment:
  #     KAFKA_BROKERCONNECT: kafka-1:19092,kafka-2:19093,kafka-3:19094
  #     JVM_OPTS: '-Xms128M -Xmx256M'
  #   depends_on:
  #     kafka-1:
  #       condition: service_healthy
  #     kafka-2:
  #       condition: service_healthy
  #     kafka-3:
  #       condition: service_healthy
  #   networks:
  #     - backend-network

volumes:
  postgres_data:
    driver: local
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  pgadmin_data:
    driver: local
  grafana_data:
    driver: local

networks:
  backend-network:
    driver: bridge