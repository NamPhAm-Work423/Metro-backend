x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

x-restart: &default-restart
  restart: unless-stopped

x-deploy: &default-deploy
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 512M
      reservations:
        cpus: '0.25'
        memory: 256M

 

services:
  # Public entry
  nginx-proxy:
    image: nginx:1.25-alpine
    container_name: nginx-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
    depends_on:
      api-gateway:
        condition: service_healthy
      webhook:
        condition: service_healthy
      grafana:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      alertmanager:
        condition: service_healthy
      loki:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart

  # Microservices (use images from GHCR, env from ../env)
  api-gateway:
    image: ${REGISTRY}/metro-api-gateway:${IMAGE_TAG}
    container_name: api-gateway
    env_file:
      - /opt/env/api-gateway.env
    expose:
      - "8000"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      promtail:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  auth-service:
    image: ${REGISTRY}/metro-auth-service:${IMAGE_TAG}
    container_name: auth-service
    env_file:
      - /opt/env/auth-service.env
    environment:
      - NEED_EMAIL_VERIFICATION=true  # Require email verification in production
      - NEED_API_KEY=false
      - SEND_ACCESS_TOKEN_TO_CLIENT=false
    expose:
      - "8001"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  user-service:
    image: ${REGISTRY}/metro-user-service:${IMAGE_TAG}
    container_name: user-service
    env_file:
      - /opt/env/user-service.env
    expose:
      - "8002"
      - "50054"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    volumes:
      - ./libs:/libs:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  transport-service:
    image: ${REGISTRY}/metro-transport-service:${IMAGE_TAG}
    container_name: transport-service
    env_file:
      - /opt/env/transport-service.env
    expose:
      - "8003"
      - "50051"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  ticket-service:
    image: ${REGISTRY}/metro-ticket-service:${IMAGE_TAG}
    container_name: ticket-service
    env_file:
      - /opt/env/ticket-service.env
    expose:
      - "8004"
      - "50052"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    volumes:
      - ./libs:/libs:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  public-service:
    image: ${REGISTRY}/metro-public-service:${IMAGE_TAG}
    container_name: public-service
    env_file:
      - /opt/env/public-service.env
    expose:
      - "8005"
    depends_on:
      transport-service:
        condition: service_healthy
      ticket-service:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      promtail:
        condition: service_started
    volumes:
      - qr_images:/app/src/public/qr 
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  scheduler-service:
    image: ${REGISTRY}/metro-scheduler-service:${IMAGE_TAG}
    container_name: scheduler-service
    env_file:
      - /opt/env/scheduler-service.env
    expose:
      - "50060"   # gRPC
      - "8010"    # HTTP health
    depends_on:
      ticket-service:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8010/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  payment-service:
    image: ${REGISTRY}/metro-payment-service:${IMAGE_TAG}
    container_name: payment-service
    env_file:
      - /opt/env/payment-service.env
    expose:
      - "8006"
    depends_on:
      postgres:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8006/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  report-service:
    image: ${REGISTRY}/metro-report-service:${IMAGE_TAG}
    container_name: report-service
    env_file:
      - /opt/env/report-service.env
    expose:
      - "8007"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','8007'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  control-service:
    image: ${REGISTRY}/metro-control-service:${IMAGE_TAG}
    container_name: control-service
    env_file:
      - /opt/env/control-service.env
    expose:
      - "8008"
      - "50053"
    depends_on:
      transport-service:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','8008'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  notification-service:
    image: ${REGISTRY}/metro-notification-service:${IMAGE_TAG}
    container_name: notification-service
    env_file:
      - /opt/env/notification-service.env
    expose:
      - "8009"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      promtail:
        condition: service_started
      api-gateway:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8009/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  # Webhook Service - External port for PayPal and other webhook providers
  webhook:
    image: ${REGISTRY}/metro-webhook:${IMAGE_TAG}
    container_name: webhook
    ports:
      - "3003:3003"  # External port for webhook providers (PayPal, etc.)
    env_file:
      - /opt/env/webhook.env
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy

  management-service:
    image: ${REGISTRY}/metro-management-service:${IMAGE_TAG}
    container_name: management-service
    env_file:
      - /opt/env/management-service.env
    expose:
      - "3001"
    depends_on:
      postgres:
        condition: service_healthy
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      promtail:
        condition: service_started
    networks:
      - backend-network
    logging: *default-logging
    <<:
      - *default-restart
      - *default-deploy
    healthcheck:
      test: ["CMD", "python", "-c", "import os,urllib.request; port=os.getenv('PORT','3001'); urllib.request.urlopen(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # MongoDB for production
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    env_file:
      - /opt/env/init_db.env
    expose:
      - "27017"  # Internal only for security
    volumes:
      - mongodb_data:/data/db
      - ./init_mongo.sh:/docker-entrypoint-initdb.d/init_mongo.sh:ro
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "mongosh --username $$MONGO_INITDB_ROOT_USERNAME --password $$MONGO_INITDB_ROOT_PASSWORD --authenticationDatabase admin --eval 'db.runCommand({ ping: 1 })' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 40s
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    <<: *default-restart

  # MongoDB management interface - DEVELOPMENT/STAGING ONLY
  mongo-express:
    image: mongo-express:1.0.2
    container_name: mongo-express
    env_file:
      - /opt/env/init_db.env
    expose:
      - "8081"  # Internal only - access via nginx /mongo-express/
    depends_on:
      mongodb:
        condition: service_healthy
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    profiles:
      - admin-tools  # Only start with --profile admin-tools

  # Infra (internal-only)
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    env_file:
      - /opt/env/init_db.env
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init_db.sh:/docker-entrypoint-initdb.d/init_db.sh:ro
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
  # pgAdmin - DEVELOPMENT/STAGING ONLY - Remove in production
  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    env_file:
      - /opt/env/init_db.env
    expose:
      - "5050"  # Internal only - access via nginx /pgadmin/
    depends_on:
      - postgres
    networks:
      - backend-network
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      - ./servers.json:/pgadmin4/servers.json:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5050/misc/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    profiles:
      - admin-tools  # Only start with --profile admin-tools



  redis:
    image: redis:7-alpine
    container_name: redis
    env_file:
      - /opt/env/init_db.env
    command: 
      - sh
      - -c
      - |
        if [ -z "$$REDIS_PASSWORD" ]; then
          echo "ERROR: REDIS_PASSWORD is not set or empty"
          exit 1
        fi
        echo "Starting Redis with authentication..."
        exec redis-server --requirepass "$$REDIS_PASSWORD" --appendonly yes --save 60 1
    volumes:
      - redis_data:/data
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "$${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 5
      ZOOKEEPER_INIT_LIMIT: 10
    expose:
      - "2181"
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  kafka-1:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-1
    expose:
      - "9092"
      - "19092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092
      KAFKA_HEAP_OPTS: "-Xms256M -Xmx256M"
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT_MS: "60000"
      KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS: "60000"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:19092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 90s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  kafka-2:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-2
    expose:
      - "9093"
      - "19093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:19093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 2
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:19093", "--list"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 90s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
  kafka-3:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-3
    expose:
      - "9094"
      - "19094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:19094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 3
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19094
      KAFKA_HEAP_OPTS: "-Xms256M -Xmx256M"
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT_MS: "60000"
      KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS: "60000"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:19094", "--list"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 90s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
          
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./management-service/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./management-service/monitoring/prometheus/alert-rules.yml:/etc/prometheus/alert-rules.yml:ro
      - ./management-service/monitoring/prometheus/services.json:/etc/prometheus/services.json:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    ports:
      - "9090:9090"
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      api-gateway:
        condition: service_healthy
      auth-service:
        condition: service_healthy
      user-service:
        condition: service_healthy
      transport-service:
        condition: service_healthy
      ticket-service:
        condition: service_healthy
      public-service:
        condition: service_healthy
      payment-service:
        condition: service_healthy
      report-service:
        condition: service_healthy
      management-service:
        condition: service_healthy

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./management-service/monitoring/prometheus/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    ports:
      - "9093:9093"
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      prometheus:
        condition: service_healthy

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SERVER_ROOT_URL=https://api.metrohcm.io.vn/grafana
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./dashboard/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./dashboard/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./dashboard/grafana/dashboards:/var/lib/grafana/dashboards:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
      jaeger:
        condition: service_healthy
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart

  promtail:
    image: grafana/promtail:2.9.4
    container_name: promtail
    expose:
      - "1514"
      - "9080"
    ports:
      - "127.0.0.1:1514:1514"
    command:
      - -config.file=/etc/promtail/config.yml
      - -config.expand-env=true
    volumes:
      - ./management-service/monitoring/promtail/promtail-prod-config.yml:/etc/promtail/config.yml:ro
    depends_on:
      - loki
    networks:
      - backend-network
    <<: *default-restart

  # Redis management interface - DEVELOPMENT/STAGING ONLY  
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    env_file:
      - /opt/env/init_db.env
    command:
      - sh
      - -c
      - |
        if [ -z "$$REDIS_PASSWORD" ]; then
          echo "ERROR: REDIS_PASSWORD is not set or empty"
          exit 1
        fi
        echo "Starting Redis Commander with authentication..."
        exec node ./bin/redis-commander --redis-port 6379 --redis-host redis --redis-password "$$REDIS_PASSWORD"
    expose:
      - "8081"  # Internal only - access via nginx /redis-commander/
    depends_on:
      - redis
    networks:
      - backend-network
    logging: *default-logging
    <<: *default-restart
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    profiles:
      - admin-tools  # Only start with --profile admin-tools


  loki:
    image: grafana/loki:2.9.4
    container_name: loki
    expose:
      - "3100"
    ports:
      - "127.0.0.1:3100:3100"
    command:
      - -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./management-service/monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    networks:
      - backend-network
    logging: *default-logging
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    <<:
      - *default-restart
      - *default-deploy

  jaeger:
    image: jaegertracing/all-in-one:1.50
    container_name: jaeger
    expose:
      - "16686"
      - "14268"
      - "14250"
      - "6831"
      - "6832"
      - "5778"
    ports:
      - "127.0.0.1:16686:16686"  # Jaeger UI (internal access only)
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - COLLECTOR_ZIPKIN_HOST_PORT=9411
      - SPAN_STORAGE_TYPE=badger
      - BADGER_EPHEMERAL=false
      - BADGER_DIRECTORY_VALUE=/badger/data
      - BADGER_DIRECTORY_KEY=/badger/key
    volumes:
      - jaeger_data:/badger
    networks:
      - backend-network
    logging: *default-logging
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:16686"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    <<:
      - *default-restart
      - *default-deploy


volumes:
  postgres_data:
    driver: local
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  grafana_data:
    driver: local
  pgadmin_data:
    driver: local
  loki_data:
    driver: local
  jaeger_data:
    driver: local
  qr_images:
    driver: local
    
networks:
  backend-network:
    driver: bridge
    external: false