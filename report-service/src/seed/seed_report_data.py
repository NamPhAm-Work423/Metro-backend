"""
Seed data for Report Service - Metro HCM Passenger Usage Analytics
Generates realistic passenger ticket usage data based on transport service routes and stations
"""

import asyncio
import random
from datetime import datetime, timedelta
from typing import List, Dict, Any
import uuid

from ..config.database import SessionLocal
from ..models.report_model import Report, ReportItem, ReportTemplate, ReportSchedule, EventLog, MetricSnapshot, TicketEventView
from ..config.logger import logger

# Metro routes data from transport service
ROUTES_DATA = [
    {
        'routeId': 'tuyen-metro-so-1-ben-thanh-suoi-tien',
        'name': 'Tuy·∫øn Metro s·ªë 1 (B·∫øn Th√†nh - Su·ªëi Ti√™n)',
        'stations': [
            'BX. Mi·ªÅn ƒê√¥ng m·ªõi', 'Su·ªëi Ti√™n', 'C√¥ng ngh·ªá cao', 'Th·ªß ƒê·ª©c', 'B√¨nh Th√°i',
            'Ph∆∞·ªõc Long', 'R·∫°ch Chi·∫øc', 'An Ph√∫', 'Th·∫£o ƒêi·ªÅn', 'C·∫ßu S√†i G√≤n',
            'VƒÉn Th√°nh', 'Ba Son', 'Nh√† h√°t', 'B·∫øn Th√†nh'
        ]
    },
    {
        'routeId': 'tuyen-metro-so-2-bx-an-suong-moi-cat-lai',
        'name': 'Tuy·∫øn Metro s·ªë 2 (BX. An S∆∞∆°ng M·ªõi - C√°t L√°i)',
        'stations': [
            'BX. An S∆∞∆°ng M·ªõi', 'T√¢n Th·ªõi Nh·∫•t', 'Tham L∆∞∆°ng', 'Ph·∫°m VƒÉn B·∫°ch', 'B√† Qu·∫πo',
            'Nguy·ªÖn H·ªìng ƒê√†o', 'ƒê·ªìng ƒêen', 'B·∫£y Hi·ªÅn', 'Ph·∫°m VƒÉn Hai', 'L√™ Th·ªã Ri√™ng',
            'H√≤a H∆∞ng', 'D√¢n Ch·ªß', 'Tao ƒê√†n', 'B·∫øn Th√†nh', 'M√™ Linh',
            'Qu·∫£ng Tr∆∞·ªùng Th·ªß Thi√™m', 'Tr·∫ßn N√£o', 'B√¨nh Kh√°nh', 'Ga Th·ªß Thi√™m',
            'B√¨nh Tr∆∞ng', 'ƒê·ªìng VƒÉn C·ªëng', 'C√°t L√°i'
        ]
    },
    {
        'routeId': 'tuyen-metro-so-3a-bx-mien-tay-moi-ben-thanh',
        'name': 'Tuy·∫øn Metro s·ªë 3a (BX. Mi·ªÅn T√¢y M·ªõi - B·∫øn Th√†nh)',
        'stations': [
            'BX. Mi·ªÅn T√¢y M·ªõi', 'T√¢n Ki√™n', 'An L·∫°c', 'C√¥ng Vi√™n Ph√∫ L√¢m', 'Ph√∫ L√¢m',
            'C√¢y G√µ', 'Ch·ª£ L·ªõn', 'Thu·∫≠n Ki·ªÅu', 'VƒÉn Lang', 'An ƒê√¥ng',
            'C·ªông H√≤a', '23 Th√°ng 9', 'B·∫øn Th√†nh'
        ]
    },
    {
        'routeId': 'tuyen-metro-so-3b-cong-hoa-ga-di-an',
        'name': 'Tuy·∫øn Metro s·ªë 3b (C·ªông H√≤a - Ga Dƒ© An)',
        'stations': [
            'C·ªông H√≤a', 'Tao ƒê√†n', 'Dinh ƒê·ªôc L·∫≠p', 'H·ªì Con R√πa', 'Th·∫£o C·∫ßm Vi√™n',
            'Th·ªã Ngh√®', 'H√†ng Xanh', 'X√¥ Vi·∫øt Ngh·ªá Tƒ©nh', 'B√¨nh Tri·ªáu',
            'Hi·ªáp B√¨nh Ph∆∞·ªõc', 'Tam B√¨nh ‚Äì G√≤ D∆∞a', 'S√≥ng Th·∫ßn', 'Ga Dƒ© An'
        ]
    },
    {
        'routeId': 'tuyen-metro-so-4-thuan-an-nha-be',
        'name': 'Tuy·∫øn Metro s·ªë 4 (Thu·∫≠n An - Nh√† B√®)',
        'stations': [
            'Thu·∫≠n An', 'L√°i Thi√™u', 'Ph√∫ Long', 'Th·∫°nh L·ªôc', 'Th·∫°nh Xu√¢n', 'X√≥m M·ªõi',
            'B·ªánh Vi·ªán G√≤ V·∫•p', 'Nguy·ªÖn VƒÉn L∆∞·ª£ng', 'Quang Trung', 'C√¥ng Vi√™n Gia ƒê·ªãnh',
            'Nguy·ªÖn Ki·ªám', 'Ph√∫ Nhu·∫≠n', 'C·∫ßu Ki·ªáu', 'C√¥ng Vi√™n L√™ VƒÉn T√°m',
            'H·ªì Con R√πa', 'B·∫øn Th√†nh', 'Kh√°nh H·ªôi', 'T√¢n H∆∞ng', 'T√¢n Phong',
            'Nguy·ªÖn VƒÉn Linh', 'H·ªì B√°n Nguy·ªát', 'Nam S√†i G√≤n', 'Ph√∫ M·ªπ', 'Nh√† B√®'
        ]
    },
    {
        'routeId': 'tuyen-metro-so-5-bx-can-giuoc-cau-sai-gon',
        'name': 'Tuy·∫øn Metro s·ªë 5 (BX. C·∫ßn Giu·ªôc - C·∫ßu S√†i G√≤n)',
        'stations': [
            'B·∫øn Xe C·∫ßn Giu·ªôc', 'B√¨nh H∆∞ng', 'T·∫° Quang B·ª≠u', 'X√≥m C·ªßi', 'Thu·∫≠n Ki·ªÅu',
            'Ph√∫ Th·ªç', 'B√°ch Khoa', 'B·∫Øc H·∫£i', 'Ch·ª£ T√¢n B√¨nh', 'B·∫£y Hi·ªÅn',
            'LƒÉng Cha C·∫£', 'Ho√†ng VƒÉn Th·ª•', 'Ph√∫ Nhu·∫≠n', 'Nguy·ªÖn VƒÉn ƒê·∫≠u',
            'B√† Chi·ªÉu', 'H√†ng Xanh', 'C·∫ßu S√†i G√≤n'
        ]
    },
    {
        'routeId': 'tuyen-metro-so-6-quoc-lo-1a-cong-hoa',
        'name': 'Tuy·∫øn Metro s·ªë 6 (Qu·ªëc L·ªô 1A - C·ªông H√≤a)',
        'stations': [
            'Qu·ªëc L·ªô 1A', 'B√¨nh H∆∞ng H√≤a', 'S∆°n K·ª≥', 'Nguy·ªÖn S∆°n', 'B·ªën X√£',
            'H√≤a B√¨nh', 'ƒê·∫ßm Sen', 'L√£nh Binh ThƒÉng', 'Ph√∫ Th·ªç', 'Th√†nh Th√°i',
            'L√Ω Th√°i T·ªï', 'C·ªông H√≤a'
        ]
    }
]

# Major interchange stations with higher traffic
MAJOR_STATIONS = {
    'B·∫øn Th√†nh': 3.5,  # Main hub
    'C·ªông H√≤a': 2.8,   # Major interchange
    'C·∫ßu S√†i G√≤n': 2.2,
    'Tao ƒê√†n': 2.0,
    'H·ªì Con R√πa': 1.8,
    'Thu·∫≠n Ki·ªÅu': 1.6,
    'B·∫£y Hi·ªÅn': 1.5,
    'Ph√∫ Nhu·∫≠n': 1.4,
    'H√†ng Xanh': 1.3
}

# Peak hour multipliers (5h-23h)
PEAK_HOURS = {
    5: 0.3,   # Early morning
    6: 1.8,   # Morning rush start
    7: 2.5,   # Peak morning rush
    8: 2.8,   # Peak morning rush
    9: 2.2,   # Morning rush end
    10: 1.2,  # Off-peak
    11: 1.0,  # Off-peak
    12: 1.3,  # Lunch time
    13: 1.1,  # Afternoon
    14: 1.0,  # Off-peak
    15: 1.0,  # Off-peak
    16: 1.2,  # Afternoon
    17: 2.0,  # Evening rush start
    18: 2.6,  # Peak evening rush
    19: 2.3,  # Evening rush end
    20: 1.5,  # Evening
    21: 1.2,  # Evening
    22: 0.8,  # Late evening
    23: 0.4   # Late night
}

def generate_station_id(station_name: str) -> str:
    """Generate station ID consistent with transport service's seedStations.js createStationId"""
    import re
    import unicodedata

    # Lowercase and decompose Vietnamese characters
    text = station_name.lower()
    text = unicodedata.normalize('NFD', text)

    # Remove diacritics
    text = ''.join(ch for ch in text if unicodedata.category(ch) != 'Mn')

    # Replace ƒë/ƒê with d
    text = text.replace('ƒë', 'd').replace('ƒê'.lower(), 'd')

    # Remove special characters except spaces (keep a-z, 0-9 and space)
    text = re.sub(r'[^a-z0-9\s]', '', text)

    # Replace spaces with hyphens
    text = re.sub(r'\s+', '-', text)

    # Collapse multiple hyphens
    text = re.sub(r'-+', '-', text)

    # Trim leading/trailing hyphens
    text = text.strip('-')

    return text

def get_base_usage_for_station(station_name: str) -> int:
    """Get base usage multiplier for station based on importance"""
    return MAJOR_STATIONS.get(station_name, 1.0)

def calculate_hourly_usage(hour: int, station_name: str, route_id: str) -> int:
    """Calculate realistic hourly usage based on time and station"""
    base_usage = get_base_usage_for_station(station_name)
    peak_multiplier = PEAK_HOURS.get(hour, 1.0)
    
    # Route-specific adjustments
    route_multiplier = 1.0
    if 'so-1' in route_id:  # Main line
        route_multiplier = 1.3
    elif 'so-2' in route_id:  # Longest line
        route_multiplier = 1.2
    elif 'so-6' in route_id:  # Shortest line
        route_multiplier = 0.8
    
    # Random variation (¬±20%)
    variation = random.uniform(0.8, 1.2)
    
    # Base passengers per hour (reduced for faster seeding)
    base_passengers = 5  # Reduced from 50 to 5
    
    return int(base_passengers * base_usage * peak_multiplier * route_multiplier * variation)

def generate_event_logs(start_date: datetime, days: int = 7) -> List[Dict[str, Any]]:
    """Generate universal event logs for all system events"""
    events = []
    
    for day in range(days):
        current_date = start_date + timedelta(days=day)
        
        for route in ROUTES_DATA:
            for station_name in route['stations']:
                station_id = generate_station_id(station_name)
                
                for hour in range(5, 24):  # 5h to 23h
                    usage_count = calculate_hourly_usage(hour, station_name, route['routeId'])
                    
                    # Generate individual ticket usage events
                    for _ in range(usage_count):
                        # Random minute within the hour
                        minute = random.randint(0, 59)
                        event_time = current_date.replace(hour=hour, minute=minute, second=0, microsecond=0)
                        
                        # Generate random passenger and ticket IDs
                        passenger_id = f"passenger_{uuid.uuid4().hex[:8]}"
                        ticket_id = f"ticket_{uuid.uuid4().hex[:8]}"
                        usage_type = 'entry' if random.random() > 0.3 else 'exit'
                        
                        event_data = {
                            'id': str(uuid.uuid4()),
                            'event_type': 'ticket.used',
                            'event_category': 'ticket',
                            'entity_id': ticket_id,
                            'entity_type': 'ticket',
                            'event_data': {
                                'ticketId': ticket_id,
                                'passengerId': passenger_id,
                                'usageData': {
                                    'stationId': station_id,
                                    'stationName': station_name,
                                    'routeId': route['routeId'],
                                    'routeName': route['name'],
                                    'usageType': usage_type
                                },
                                'usedAt': event_time.isoformat()
                            },
                            'processed_data': {
                                'passenger_id': passenger_id,
                                'station_id': station_id,
                                'station_name': station_name,
                                'route_id': route['routeId'],
                                'route_name': route['name'],
                                'usage_type': usage_type
                            },
                            'event_timestamp': event_time,
                            'source_service': 'ticket-service',
                            'correlation_id': f"corr_{uuid.uuid4().hex[:12]}"
                        }
                        events.append(event_data)
    
    return events

def generate_ticket_event_views(start_date: datetime, days: int = 7) -> List[Dict[str, Any]]:
    """Generate optimized ticket event views for analytics"""
    views = []
    
    for day in range(days):
        current_date = start_date + timedelta(days=day)
        
        for route in ROUTES_DATA:
            for station_name in route['stations']:
                station_id = generate_station_id(station_name)
                
                for hour in range(5, 24):
                    usage_count = calculate_hourly_usage(hour, station_name, route['routeId'])
                    
                    for _ in range(usage_count):
                        minute = random.randint(0, 59)
                        event_time = current_date.replace(hour=hour, minute=minute, second=0, microsecond=0)
                        
                        passenger_id = f"passenger_{uuid.uuid4().hex[:8]}"
                        ticket_id = f"ticket_{uuid.uuid4().hex[:8]}"
                        usage_type = 'entry' if random.random() > 0.3 else 'exit'
                        
                        view_data = {
                            'id': str(uuid.uuid4()),
                            'ticket_id': ticket_id,
                            'passenger_id': passenger_id,
                            'event_type': 'used',
                            'event_timestamp': event_time,
                            'station_id': station_id,
                            'station_name': station_name,
                            'route_id': route['routeId'],
                            'route_name': route['name'],
                            'usage_type': usage_type,
                            'date_partition': event_time.strftime('%Y-%m-%d'),
                            'hour_partition': hour
                        }
                        views.append(view_data)
    
    return views

def generate_metric_snapshots(start_date: datetime, days: int = 7) -> List[Dict[str, Any]]:
    """Generate time-series metric snapshots"""
    snapshots = []
    
    for day in range(days):
        current_date = start_date + timedelta(days=day)
        
        # Hourly snapshots for each station
        for route in ROUTES_DATA:
            for station_name in route['stations']:
                station_id = generate_station_id(station_name)
                
                for hour in range(5, 24):
                    hour_time = current_date.replace(hour=hour, minute=0, second=0, microsecond=0)
                    usage_count = calculate_hourly_usage(hour, station_name, route['routeId'])
                    
                    # Usage count metric
                    usage_snapshot = {
                        'id': str(uuid.uuid4()),
                        'metric_name': 'hourly_station_usage',
                        'metric_category': 'usage',
                        'metric_value': float(usage_count),
                        'metric_unit': 'count',
                        'dimensions': {
                            'station_id': station_id,
                            'station_name': station_name,
                            'route_id': route['routeId'],
                            'route_name': route['name'],
                            'hour': hour
                        },
                        'timestamp': hour_time,
                        'period_type': 'hourly',
                        'aggregation_type': 'sum',
                        'sample_count': usage_count
                    }
                    snapshots.append(usage_snapshot)
        
        # Daily aggregate metrics
        daily_total = sum(calculate_hourly_usage(h, s, r['routeId']) 
                         for r in ROUTES_DATA 
                         for s in r['stations'] 
                         for h in range(5, 24))
        
        daily_snapshot = {
            'id': str(uuid.uuid4()),
            'metric_name': 'daily_total_usage',
            'metric_category': 'usage',
            'metric_value': float(daily_total),
            'metric_unit': 'count',
            'dimensions': {
                'date': current_date.strftime('%Y-%m-%d')
            },
            'timestamp': current_date.replace(hour=23, minute=59, second=0),
            'period_type': 'daily',
            'aggregation_type': 'sum',
            'sample_count': daily_total
        }
        snapshots.append(daily_snapshot)
    
    return snapshots

def generate_additional_metrics(start_date: datetime, days: int = 7) -> List[Dict[str, Any]]:
    """Generate additional metrics for comprehensive reporting"""
    metrics = []
    
    for day in range(days):
        current_date = start_date + timedelta(days=day)
        
        # Daily summary metrics
        daily_metrics = [
            {
                'id': str(uuid.uuid4()),
                'metric_name': 'daily_total_passengers',
                'metric_value': random.randint(45000, 65000),
                'metric_unit': 'count',
                'report_id': None,
                'timestamp': current_date.replace(hour=23, minute=59, second=0),
                'metadata_json': {
                    'date': current_date.date().isoformat(),
                    'total_routes': len(ROUTES_DATA),
                    'total_stations': sum(len(route['stations']) for route in ROUTES_DATA)
                }
            },
            {
                'id': str(uuid.uuid4()),
                'metric_name': 'daily_revenue',
                'metric_value': random.uniform(850000000, 1200000000),  # VND
                'metric_unit': 'currency',
                'report_id': None,
                'timestamp': current_date.replace(hour=23, minute=59, second=0),
                'metadata_json': {
                    'date': current_date.date().isoformat(),
                    'currency': 'VND',
                    'average_fare': random.uniform(8000, 15000)
                }
            },
            {
                'id': str(uuid.uuid4()),
                'metric_name': 'peak_hour_passengers',
                'metric_value': random.randint(8000, 12000),
                'metric_unit': 'count',
                'report_id': None,
                'timestamp': current_date.replace(hour=18, minute=0, second=0),
                'metadata_json': {
                    'date': current_date.date().isoformat(),
                    'peak_hour': '18:00',
                    'busiest_station': 'B·∫øn Th√†nh'
                }
            }
        ]
        metrics.extend(daily_metrics)
    
    return metrics

def create_sample_reports() -> List[Dict[str, Any]]:
    """Create sample reports for demonstration"""
    reports = []
    
    # Daily report
    daily_report = {
        'id': str(uuid.uuid4()),
        'title': 'B√°o c√°o h√†ng ng√†y - Metro HCM',
        'description': 'B√°o c√°o t·ªïng h·ª£p ho·∫°t ƒë·ªông Metro HCM h√†ng ng√†y',
        'report_type': 'daily',
        'status': 'completed',
        'file_path': '/reports/daily_2024_01_15.html',
        'report_metadata': {
            'generated_at': datetime.now().isoformat(),
            'period': '2024-01-15',
            'total_passengers': 52000,
            'total_revenue': 950000000,
            'peak_hour': '18:00'
        },
        'created_at': datetime.now(),
        'updated_at': datetime.now(),
        'completed_at': datetime.now()
    }
    reports.append(daily_report)
    
    # Weekly report
    weekly_report = {
        'id': str(uuid.uuid4()),
        'title': 'B√°o c√°o tu·∫ßn - Metro HCM',
        'description': 'B√°o c√°o t·ªïng h·ª£p ho·∫°t ƒë·ªông Metro HCM tu·∫ßn t·ª´ 15/01/2024 - 21/01/2024',
        'report_type': 'weekly',
        'status': 'completed',
        'file_path': '/reports/weekly_2024_week_03.html',
        'report_metadata': {
            'generated_at': datetime.now().isoformat(),
            'period': '2024-W03',
            'total_passengers': 365000,
            'total_revenue': 6650000000,
            'average_daily': 52000
        },
        'created_at': datetime.now(),
        'updated_at': datetime.now(),
        'completed_at': datetime.now()
    }
    reports.append(weekly_report)
    
    return reports

def create_report_templates() -> List[Dict[str, Any]]:
    """Create report templates for different report types"""
    templates = []
    
    templates_data = [
        {
            'id': str(uuid.uuid4()),
            'name': 'Daily Operations Report',
            'description': 'Template for daily Metro operations report',
            'template_type': 'daily',
            'config': {
                'sections': [
                    {'type': 'summary', 'title': 'T·ªïng quan'},
                    {'type': 'passenger_metrics', 'title': 'S·ªë li·ªáu h√†nh kh√°ch'},
                    {'type': 'revenue_metrics', 'title': 'Doanh thu'},
                    {'type': 'station_analysis', 'title': 'Ph√¢n t√≠ch ga'},
                    {'type': 'route_analysis', 'title': 'Ph√¢n t√≠ch tuy·∫øn'}
                ],
                'charts': ['passenger_flow', 'revenue_trend', 'station_heatmap'],
                'format': 'html'
            },
            'is_active': 1
        },
        {
            'id': str(uuid.uuid4()),
            'name': 'Weekly Performance Report',
            'description': 'Template for weekly Metro performance analysis',
            'template_type': 'weekly',
            'config': {
                'sections': [
                    {'type': 'weekly_summary', 'title': 'T·ªïng quan tu·∫ßn'},
                    {'type': 'daily_breakdown', 'title': 'Chi ti·∫øt theo ng√†y'},
                    {'type': 'trend_analysis', 'title': 'Ph√¢n t√≠ch xu h∆∞·ªõng'},
                    {'type': 'comparison', 'title': 'So s√°nh v·ªõi tu·∫ßn tr∆∞·ªõc'}
                ],
                'charts': ['weekly_trend', 'daily_comparison', 'performance_metrics'],
                'format': 'pdf'
            },
            'is_active': 1
        },
        {
            'id': str(uuid.uuid4()),
            'name': 'Monthly Analytics Report',
            'description': 'Template for monthly Metro analytics and insights',
            'template_type': 'monthly',
            'config': {
                'sections': [
                    {'type': 'executive_summary', 'title': 'T√≥m t·∫Øt ƒëi·ªÅu h√†nh'},
                    {'type': 'key_metrics', 'title': 'Ch·ªâ s·ªë ch√≠nh'},
                    {'type': 'detailed_analysis', 'title': 'Ph√¢n t√≠ch chi ti·∫øt'},
                    {'type': 'recommendations', 'title': 'Khuy·∫øn ngh·ªã'}
                ],
                'charts': ['monthly_trends', 'performance_dashboard', 'forecast'],
                'format': 'pdf'
            },
            'is_active': 1
        }
    ]
    
    for template_data in templates_data:
        template_data.update({
            'created_at': datetime.now(),
            'updated_at': datetime.now()
        })
        templates.append(template_data)
    
    return templates

def seed_report_data():
    """Main function to seed all report data (synchronous for thread execution)"""
    try:
        logger.info("Starting report service seed data generation...")
        
        db = SessionLocal()
        
        # Clear existing data
        logger.info("Clearing existing report data...")
        try:
            db.query(TicketEventView).delete()
            db.query(MetricSnapshot).delete()
            db.query(EventLog).delete()
            db.query(ReportItem).delete()
            db.query(Report).delete()
            db.query(ReportTemplate).delete()
            db.query(ReportSchedule).delete()
            db.commit()
            logger.info("Existing data cleared successfully")
        except Exception as e:
            logger.warning(f"Error clearing data (may be first run): {e}")
            db.rollback()
        
        # Generate date range (last 7 days)
        end_date = datetime.now().replace(hour=23, minute=59, second=0, microsecond=0)
        start_date = end_date - timedelta(days=6)
        
        # Generate structured event logs (reduced for performance)
        logger.info("Generating event logs...")
        event_logs = generate_event_logs(start_date, days=2)  # Reduced from 7 to 2 days
        logger.info(f"Generated {len(event_logs)} event logs")
        
        # Generate ticket event views
        logger.info("Generating ticket event views...")
        ticket_views = generate_ticket_event_views(start_date, days=2)  # Reduced from 7 to 2 days
        logger.info(f"Generated {len(ticket_views)} ticket event views")
        
        # Generate metric snapshots
        logger.info("Generating metric snapshots...")
        metric_snapshots = generate_metric_snapshots(start_date, days=2)  # Reduced from 7 to 2 days
        logger.info(f"Generated {len(metric_snapshots)} metric snapshots")
        
        # Create report templates
        logger.info("Creating report templates...")
        templates = create_report_templates()
        for template_data in templates:
            template = ReportTemplate(**template_data)
            db.add(template)
        db.commit()
        logger.info(f"Created {len(templates)} report templates")
        
        # Create sample reports
        logger.info("Creating sample reports...")
        reports = create_sample_reports()
        for report_data in reports:
            report = Report(**report_data)
            db.add(report)
        db.commit()
        logger.info(f"Created {len(reports)} sample reports")
        
        # Insert event logs in batches
        logger.info("Inserting event logs into database...")
        batch_size = 1000
        for i in range(0, len(event_logs), batch_size):
            batch = event_logs[i:i + batch_size]
            for event_data in batch:
                event = EventLog(**event_data)
                db.add(event)
            try:
                db.commit()
                logger.info(f"Inserted event batch {i//batch_size + 1}/{(len(event_logs) + batch_size - 1)//batch_size}")
            except Exception as e:
                logger.error(f"Error inserting event batch: {e}")
                db.rollback()
        
        # Insert ticket event views
        logger.info("Inserting ticket event views...")
        for i in range(0, len(ticket_views), batch_size):
            batch = ticket_views[i:i + batch_size]
            for view_data in batch:
                view = TicketEventView(**view_data)
                db.add(view)
            try:
                db.commit()
                logger.info(f"Inserted view batch {i//batch_size + 1}/{(len(ticket_views) + batch_size - 1)//batch_size}")
            except Exception as e:
                logger.error(f"Error inserting view batch: {e}")
                db.rollback()
        
        # Insert metric snapshots
        logger.info("Inserting metric snapshots...")
        for i in range(0, len(metric_snapshots), batch_size):
            batch = metric_snapshots[i:i + batch_size]
            for snapshot_data in batch:
                snapshot = MetricSnapshot(**snapshot_data)
                db.add(snapshot)
            try:
                db.commit()
                logger.info(f"Inserted snapshot batch {i//batch_size + 1}/{(len(metric_snapshots) + batch_size - 1)//batch_size}")
            except Exception as e:
                logger.error(f"Error inserting snapshot batch: {e}")
                db.rollback()
        
        # Create sample report items
        logger.info("Creating report items...")
        report_items = []
        for report in reports:
            items_data = [
                {
                    'id': str(uuid.uuid4()),
                    'report_id': report['id'],
                    'item_type': 'metric',
                    'title': 'T·ªïng s·ªë h√†nh kh√°ch',
                    'content': {'value': 52000, 'unit': 'ng∆∞·ªùi', 'trend': '+5.2%'},
                    'order_index': 1
                },
                {
                    'id': str(uuid.uuid4()),
                    'report_id': report['id'],
                    'item_type': 'chart',
                    'title': 'Bi·ªÉu ƒë·ªì l∆∞u l∆∞·ª£ng theo gi·ªù',
                    'content': {'type': 'line', 'data': 'passenger_flow_data'},
                    'order_index': 2
                },
                {
                    'id': str(uuid.uuid4()),
                    'report_id': report['id'],
                    'item_type': 'table',
                    'title': 'Top 10 ga ƒë√¥ng nh·∫•t',
                    'content': {'headers': ['Ga', 'S·ªë l∆∞·ª£t'], 'data': 'top_stations_data'},
                    'order_index': 3
                }
            ]
            report_items.extend(items_data)
        
        for item_data in report_items:
            item = ReportItem(**item_data)
            db.add(item)
        db.commit()
        logger.info(f"Created {len(report_items)} report items")
        
        db.close()
        
        logger.info("‚úÖ Report service seed data generation completed successfully!")
        logger.info(f"üìä Generated data summary:")
        logger.info(f"   - Event logs: {len(event_logs)}")
        logger.info(f"   - Ticket event views: {len(ticket_views)}")
        logger.info(f"   - Metric snapshots: {len(metric_snapshots)}")
        logger.info(f"   - Report templates: {len(templates)}")
        logger.info(f"   - Sample reports: {len(reports)}")
        logger.info(f"   - Report items: {len(report_items)}")
        
        return {
            'event_logs': len(event_logs),
            'ticket_views': len(ticket_views),
            'metric_snapshots': len(metric_snapshots),
            'templates': len(templates),
            'reports': len(reports),
            'report_items': len(report_items)
        }
        
    except Exception as error:
        logger.error(f"‚ùå Error generating report seed data: {error}")
        raise error

if __name__ == "__main__":
    seed_report_data()
